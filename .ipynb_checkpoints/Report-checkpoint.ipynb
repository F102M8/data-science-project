{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5dd5a3f-8a3d-4268-ac9b-a0957a2c4b11",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkBlue\"> Project Report:  Game Price Prediction Project</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ef496-de13-4c2c-b9b8-1f1fdec1fd76",
   "metadata": {},
   "source": [
    "## <span style=\"color:Purple\"> 1) Introduction </span>\n",
    "\n",
    "The objective of this project is to predict the prices of video games based on various features gathered from the SteamDB website. Accurate price prediction can help developers and publishers in strategizing their marketing and sales efforts, and can assist consumers in making informed purchasing decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422597ac-1b5c-406e-953c-99b47cc2a55d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <span style=\"color:Purple\"> 2) Data Collection </span>\n",
    "The data collection phase involved web scraping from the SteamDB website to gather information on approximately 3000 video games. This phase was divided into two main steps:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f0440-293c-4eca-b6a3-620f6e3416fc",
   "metadata": {},
   "source": [
    "#### 2.1 Web Scraping Game Information\n",
    "\n",
    "In the first step, game URLs and detailed game information were scraped from the SteamDB search pages. The key features collected for each game include:\n",
    "- `NAME`: The title of the game.\n",
    "- `STORE_GENRE`: The genre(s) of the game.\n",
    "- `RATING_SCORE`: The overall rating score of the game.\n",
    "- `N_SUPPORTED_LANGUAGES`: The number of languages supported by the game.\n",
    "- `DEVELOPERS`: The developer(s) of the game.\n",
    "- `SUPPORTED_PLATFORMS`: The platforms on which the game is available.\n",
    "- `POSITIVE_REVIEWS`: The number of positive reviews.\n",
    "- `NEGATIVE_REVIEWS`: The number of negative reviews.\n",
    "- `TECHNOLOGIES`: The technologies used in the game.\n",
    "- `RELEASE_DATE`: The release date of the game.\n",
    "- `TOTAL_TWITCH_PEAK`: The peak number of viewers on Twitch.\n",
    "- `PRICE`: The price of the game.\n",
    "- `N_DLC`: The number of downloadable content (DLC) available.\n",
    "- `24_HOUR_PEAK`: The peak number of players in the last 24 hours.\n",
    "\n",
    "This step involved several challenges, including handling the large volume of data (3000 games) and ensuring the scraping process was efficient and reliable. The data collected in this step was saved in two files:\n",
    "- `game_urls.txt`: Contains URLs of the games.\n",
    "- `games_info.csv`: Contains detailed information of the games.\n",
    "\n",
    "#### 2.2 Web Scraping Game Prices\n",
    "\n",
    "In the second step, the focus was on gathering the prices of the games in USD to ensure consistency across different regions. This involved scraping the name, release date, and price of each game from their respective pages. This data was saved in:\n",
    "- `games_details.csv`: Contains the name, release date, and price of the games.\n",
    "\n",
    "*** \n",
    "\n",
    "#### Data Files and Notebooks\n",
    "\n",
    "The following files and notebooks were created and used during the data collection phase:\n",
    "1. **Data Files**:\n",
    "   - `game_urls.txt`: A text file containing URLs of the games.\n",
    "   - `games_info.csv`: A CSV file containing detailed game information.\n",
    "   - `games_details.csv`: A CSV file containing the name, release date, and price of the games.\n",
    "\n",
    "2. **Notebooks**:\n",
    "   - `webScrape_1.ipynb`: Notebook used to scrape game URLs and detailed information, resulting in `game_urls.txt` and `games_info.csv`.\n",
    "   - `webScrape_2_price.ipynb`: Notebook used to scrape game prices, resulting in `games_details.csv`.\n",
    "\n",
    "\n",
    "The data collection phase provided a comprehensive dataset that includes various features of video games and their prices. This dataset forms the foundation for the subsequent analysis and price prediction models. The challenges encountered during web scraping were addressed effectively to ensure data accuracy and completeness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139e405-8146-45ea-995c-a1661f8ddadf",
   "metadata": {},
   "source": [
    "## <span style=\"color:Purple\">B) Preprocessing</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47cb71-84e4-4691-add7-2731eb06b242",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "### 1. Introduction\r\n",
    "\r\n",
    "The preprocessing phase is crucial for ensuring that the data is clean, consistent, and ready for subsequent analysis. This phase involves handling missing values, correcting data types, creating new features, and addressing any inconsistencies. The preprocessing steps were executed in the `Preprocessing.ipynb` notebook, with `game_info.csv` and `game_details.csv` as inputs, resulting in the output file `preprocessed_game_info.csv`.\r\n",
    "\r\n",
    "### 2. Methodology\r\n",
    "\r\n",
    "#### a. Loading Data\r\n",
    "\r\n",
    "The datasets `game_info.csv` and `game_details.csv` were loaded into Pandas DataFrames to facilitate data manipulation. This step sets the foundation for all subsequent data processing tasks.\r\n",
    "\r\n",
    "#### b. Initial Data Exploration\r\n",
    "\r\n",
    "Basic exploratory data analysis was performed to understand the structure and content of the datasets. This included checking the data types of each column, identifying missing values, and generating summary statistics to get a high-level overview of the data.\r\n",
    "\r\n",
    "#### c. Removing Duplicated Games\r\n",
    "\r\n",
    "Duplicates in the dataset can lead to skewed analysis results. To prevent this, duplicate entries based on the 'NAME' column were identified and removed.\r\n",
    "\r\n",
    "#### d. Handling Missing Values\r\n",
    "\r\n",
    "Several steps were taken to handle missing values across different columns:\r\n",
    "\r\n",
    "- **General Replacement**: 'N/A' values in the dataset were standardized by replacing them with Pandas' `pd.NA`.\r\n",
    "- **'DEVELOPERS' Column**: To maintain data integrity, rows with missing values in the 'DEVELOPERS' column were dropped.\r\n",
    "- **'RELEASE_DATE' Column**: The 'RELEASE_DATE' column was processed to extract the year, creating a new 'PUBLISH_YEAR' column. Missing years were filled with the median value of the column, and the original 'RELEASE_DATE' column was subsequently dropped.\r\n",
    "- **'PRICE' Column**: Missing prices were filled using corresponding values from the `game_details.csv` file. Prices were cleaned and converted to numeric values, ensuring consistency across the dataset. Remaining rows with missing prices were dropped to avoid incomplete data entries.\r\n",
    "- **'N_SUPPORTED_LANGUAGES' Column**: Missing values were filled with a default value, and the column was cleaned and converted to an integer type to ensure proper data formatting.\r\n",
    "- **'RATING_SCORE' Column**: Missing values were filled with a placeholder, cleaned, and converted to numeric values. The placeholder values were then replaced with the mean rating score to ensure a realistic representation of the data.\r\n",
    "\r\n",
    "#### e. Data Cleaning and Feature Engineering\r\n",
    "\r\n",
    "Several columns required specific cleaning and feature engineering steps:\r\n",
    "\r\n",
    "- **'STORE_GENRE' Column**: Missing values were filled, unnecessary text was removed, and the genres were split into a list format to facilitate better analysis.\r\n",
    "- **'24_HOUR_PEAK' Column**: This column was cleaned by filling missing values and extracting relevant numerical values, which were then converted to an integer type.\r\n",
    "- **'TECHNOLOGIES' Column**: Missing values were filled with empty strings, and the technologies were split into lists for better usability during analysis.\r\n",
    "- **'TOTAL_TWITCH_PEAK' Column**: The column was split into 'TWITCH_PEAK_HOUR' and 'TWITCH_PEAK_YEAR', both of which were cleaned and converted to numeric types. The original 'TOTAL_TWITCH_PEAK' column was dropped after extracting the necessary information.\r\n",
    "- **'N_DLC' Column**: Missing values were temporarily filled and then restored. The percentage of null values was calculated to make an informed decision, and the column was dropped due to a high percentage of missing values.\r\n",
    "- **'TOTAL_REVIEW' Column**: A new column was created to represent the proportion of positive reviews out of the total reviews, providing insights into the overall sentiment and reception of the games.\r\n",
    "\r\n",
    "### 3. Data Integration\r\n",
    "\r\n",
    "The cleaned and preprocessed data from the primary dataset (`game_info.csv`) and the secondary dataset (`game_details.csv`) were merged to form a unified dataset. This step ensured that all relevant information was combined, providing a comprehensive dataset for further analysis.\r\n",
    "\r\n",
    "### 4. Final Dataset Preparation\r\n",
    "\r\n",
    "A final check was conducted to ensure all preprocessing steps were correctly applied. This included verifying that there were no remaining missing values, that all data types were correct, and that all necessary transformations had been completed. The cleaned and prepared dataset was then saved as `preprocessed_game_info.csv`.\r\n",
    "\r\n",
    "### 5. Summary\r\n",
    "\r\n",
    "In summary, the preprocessing phase involved:\r\n",
    "- Loading and exploring the data.\r\n",
    "- Removing duplicate entries.\r\n",
    "- Handling missing values across various columns.\r\n",
    "- Cleaning data and engineering new features.\r\n",
    "- Integrating datasets to form a comprehensive dataset.\r\n",
    "\r\n",
    "These steps ensured that the data was clean, consistent, and ready for subsequent analysis and modeling. The output of this phase, `preprocessed_game_info.csv`, y additional details or specific adjustments, please let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021203a2-ef8d-4a30-b5e4-da94a0218fd7",
   "metadata": {},
   "source": [
    "## <span style=\"color:Purple\">C) Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d472cc9-d122-4b4a-ae6f-46c44cb87dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
